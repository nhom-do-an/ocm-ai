# AI Training Service

Dá»‹ch vá»¥ AI Training Service cung cáº¥p cÃ¡c API Ä‘á»ƒ train vÃ  predict cÃ¡c mÃ´ hÃ¬nh machine learning cho há»‡ thá»‘ng e-commerce, bao gá»“m:

- **Recommendation Model (NeuMF)**: MÃ´ hÃ¬nh gá»£i Ã½ sáº£n pháº©m dá»±a trÃªn collaborative filtering
- **Trending Model (LightGBM)**: MÃ´ hÃ¬nh dá»± Ä‘oÃ¡n xu hÆ°á»›ng bÃ¡n hÃ ng
- **Next Item Model**: MÃ´ hÃ¬nh dá»± Ä‘oÃ¡n sáº£n pháº©m tiáº¿p theo dá»±a trÃªn lá»‹ch sá»­ mua hÃ ng

## ğŸ“‹ Má»¥c lá»¥c

- [Kiáº¿n trÃºc](#kiáº¿n-trÃºc)
- [YÃªu cáº§u há»‡ thá»‘ng](#yÃªu-cáº§u-há»‡-thá»‘ng)
- [CÃ i Ä‘áº·t vÃ  cháº¡y trÃªn Local](#cÃ i-Ä‘áº·t-vÃ -cháº¡y-trÃªn-local)
- [Build vÃ  Deploy vá»›i Docker](#build-vÃ -deploy-vá»›i-docker)
- [API Endpoints](#api-endpoints)
- [Cáº¥u hÃ¬nh](#cáº¥u-hÃ¬nh)
- [Cáº¥u trÃºc thÆ° má»¥c](#cáº¥u-trÃºc-thÆ°-má»¥c)

## ğŸ—ï¸ Kiáº¿n trÃºc

### Tá»•ng quan

Service Ä‘Æ°á»£c xÃ¢y dá»±ng báº±ng Flask, cung cáº¥p RESTful API Ä‘á»ƒ:

1. **Training**: Train cÃ¡c mÃ´ hÃ¬nh ML cho tá»«ng store
2. **Prediction**: Sá»­ dá»¥ng mÃ´ hÃ¬nh Ä‘Ã£ train Ä‘á»ƒ Ä‘Æ°a ra dá»± Ä‘oÃ¡n
3. **Caching**: Cache káº¿t quáº£ prediction Ä‘á»ƒ tÄƒng hiá»‡u suáº¥t

### CÃ¡c thÃ nh pháº§n chÃ­nh

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    Flask API Server                      â”‚
â”‚  (training_service.py - Port 5001)                      â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                 â”‚                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
â”‚ Recommendationâ”‚  â”‚   Trending   â”‚  â”‚  Next Item   â”‚
â”‚   Trainer     â”‚  â”‚   Trainer    â”‚  â”‚   Trainer    â”‚
â”‚  (NeuMF)      â”‚  â”‚  (LightGBM)  â”‚  â”‚ (Sequential) â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
        â”‚                 â”‚                 â”‚
        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                          â”‚
        â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
        â”‚                 â”‚                 â”‚
â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â–¼â”€â”€â”€â”€â”€â”€â”
â”‚   Database   â”‚  â”‚ Data Extract â”‚  â”‚ Model Cache  â”‚
â”‚  (PostgreSQL)â”‚  â”‚   (SQL)      â”‚  â”‚  Manager     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Models

#### 1. Recommendation Model (NeuMF)

- **Kiáº¿n trÃºc**: Neural Matrix Factorization
- **Input**: User-Item interactions (orders, cart)
- **Output**: Recommendation scores cho tá»«ng user-item pair
- **Use case**: Gá»£i Ã½ sáº£n pháº©m cho khÃ¡ch hÃ ng

#### 2. Trending Model (LightGBM)

- **Kiáº¿n trÃºc**: Gradient Boosting Decision Tree
- **Input**: Time series features (sales, lags, rolling stats)
- **Output**: Predicted sales cho sáº£n pháº©m
- **Use case**: Dá»± Ä‘oÃ¡n sáº£n pháº©m Ä‘ang trending

#### 3. Next Item Model

- **Kiáº¿n trÃºc**: Sequential pattern matching
- **Input**: Purchase sequences cá»§a khÃ¡ch hÃ ng
- **Output**: XÃ¡c suáº¥t sáº£n pháº©m tiáº¿p theo
- **Use case**: "KhÃ¡ch hÃ ng mua X thÆ°á»ng mua Y"

## ğŸ’» YÃªu cáº§u há»‡ thá»‘ng

- **Python**: 3.11+
- **PostgreSQL**: 12+
- **RAM**: Tá»‘i thiá»ƒu 4GB (khuyáº¿n nghá»‹ 8GB+)
- **Disk**: Tá»‘i thiá»ƒu 10GB cho models vÃ  data
- **GPU**: TÃ¹y chá»n (Ä‘á»ƒ tÄƒng tá»‘c training)

## ğŸš€ CÃ i Ä‘áº·t vÃ  cháº¡y trÃªn Local

### BÆ°á»›c 1: Clone repository

```bash
cd ai-service
```

### BÆ°á»›c 2: Táº¡o virtual environment

```bash
python3.11 -m venv venv
source venv/bin/activate  # TrÃªn Windows: venv\Scripts\activate
```

### BÆ°á»›c 3: CÃ i Ä‘áº·t dependencies

```bash
pip install --upgrade pip
pip install -r requirements.txt
```

### BÆ°á»›c 4: Cáº¥u hÃ¬nh mÃ´i trÆ°á»ng

Táº¡o file `.env` tá»« template:

```bash
cp env.example .env
```

Chá»‰nh sá»­a file `.env` vá»›i thÃ´ng tin database cá»§a báº¡n:

```env
DB_HOST=localhost
DB_PORT=5433
DB_NAME=testocm
DB_USER=zalolog
DB_PASSWORD=123456
FLASK_PORT=5001
FLASK_DEBUG=true
```

### BÆ°á»›c 5: Äáº£m báº£o PostgreSQL Ä‘ang cháº¡y

```bash
# Kiá»ƒm tra káº¿t ná»‘i
psql -h localhost -p 5433 -U zalolog -d testocm
```

### BÆ°á»›c 6: Táº¡o thÆ° má»¥c lÆ°u models

```bash
mkdir -p results
```

### BÆ°á»›c 7: Cháº¡y service

```bash
cd api
python training_service.py
```

Service sáº½ cháº¡y táº¡i: `http://localhost:5001`

### BÆ°á»›c 8: Kiá»ƒm tra health check

```bash
curl http://localhost:5001/health
```

Káº¿t quáº£ mong Ä‘á»£i:

```json
{
  "status": "healthy",
  "service": "ai-training-service",
  "version": "2.0",
  "config_loaded": true
}
```

## ğŸ³ Build vÃ  Deploy vá»›i Docker

### Option 1: Sá»­ dá»¥ng Docker Compose (Khuyáº¿n nghá»‹)

#### BÆ°á»›c 1: Cáº¥u hÃ¬nh mÃ´i trÆ°á»ng

Táº¡o file `.env`:

```bash
cp env.example .env
# Chá»‰nh sá»­a cÃ¡c biáº¿n mÃ´i trÆ°á»ng náº¿u cáº§n
```

#### BÆ°á»›c 2: Build vÃ  cháº¡y

```bash
# Build vÃ  start táº¥t cáº£ services
docker-compose up -d

# Xem logs
docker-compose logs -f ai-service

# Kiá»ƒm tra status
docker-compose ps
```

#### BÆ°á»›c 3: Kiá»ƒm tra service

```bash
curl http://localhost:5001/health
```

#### CÃ¡c lá»‡nh há»¯u Ã­ch

```bash
# Stop services
docker-compose down

# Stop vÃ  xÃ³a volumes (xÃ³a data)
docker-compose down -v

# Rebuild sau khi thay Ä‘á»•i code
docker-compose up -d --build

# Xem logs real-time
docker-compose logs -f ai-service

# VÃ o container
docker-compose exec ai-service bash
```

### Option 2: Build Docker image thá»§ cÃ´ng

#### BÆ°á»›c 1: Build image

```bash
docker build -t ai-training-service:latest .
```

#### BÆ°á»›c 2: Cháº¡y container

```bash
docker run -d \
  --name ai-service \
  -p 5001:5001 \
  -e DB_HOST=your_db_host \
  -e DB_PORT=5432 \
  -e DB_NAME=testocm \
  -e DB_USER=zalolog \
  -e DB_PASSWORD=123456 \
  -v $(pwd)/results:/app/results \
  -v $(pwd)/data:/app/data \
  ai-training-service:latest
```

#### BÆ°á»›c 3: Kiá»ƒm tra

```bash
docker logs ai-service
curl http://localhost:5001/health
```

### Production Deployment

#### 1. Build production image

```bash
docker build -t ai-training-service:prod .
```

#### 2. Tag vÃ  push lÃªn registry (náº¿u cáº§n)

```bash
docker tag ai-training-service:prod your-registry/ai-training-service:v1.0.0
docker push your-registry/ai-training-service:v1.0.0
```

#### 3. Deploy vá»›i docker-compose.prod.yml

Táº¡o file `docker-compose.prod.yml`:

```yaml
version: "3.8"

services:
  ai-service:
    image: ai-training-service:prod
    container_name: ai-training-service-prod
    restart: always
    ports:
      - "5001:5001"
    env_file:
      - .env.prod
    volumes:
      - ./results:/app/results
      - ./data:/app/data
    networks:
      - ai-network
    healthcheck:
      test:
        [
          "CMD",
          "python",
          "-c",
          "import requests; requests.get('http://localhost:5001/health')",
        ]
      interval: 30s
      timeout: 10s
      retries: 3

networks:
  ai-network:
    driver: bridge
```

Cháº¡y:

```bash
docker-compose -f docker-compose.prod.yml up -d
```

## ğŸ“¡ API Endpoints

### Health Check

```http
GET /health
```

**Response:**

```json
{
  "status": "healthy",
  "service": "ai-training-service",
  "version": "2.0",
  "config_loaded": true
}
```

### Train Recommendation Model

```http
POST /train/recommendation
Content-Type: application/json

{
  "store_id": 1
}
```

**Response:**

```json
{
  "success": true,
  "store_id": 1,
  "model_type": "recommendation",
  "metrics": {
    "train_loss": 0.45,
    "val_loss": 0.52,
    "cached_users": 150,
    "model_version": "v1.0"
  },
  "model_path": "results/store_1/recommendation/neumf_model.pth"
}
```

### Train Trending Model

```http
POST /train/trending
Content-Type: application/json

{
  "store_id": 1
}
```

**Response:**

```json
{
  "success": true,
  "store_id": 1,
  "model_type": "trending",
  "metrics": {
    "rmse": 2.34,
    "mae": 1.89,
    "cached_products": 500,
    "model_version": "v1.0"
  },
  "model_path": "results/store_1/trending/lightgbm_model.txt"
}
```

### Train Next Item Model

```http
POST /train/next-item
Content-Type: application/json

{
  "store_id": 1
}
```

**Response:**

```json
{
  "status": "success",
  "store_id": 1,
  "model_path": "results/store_1/next_item/next_item_model.pkl",
  "metrics": {
    "total_patterns": 1250,
    "avg_confidence": 0.75
  }
}
```

### Predict Recommendations

```http
POST /predict/recommendations
Content-Type: application/json

{
  "store_id": 1,
  "user_id": 123,
  "n": 10
}
```

**Response:**

```json
{
  "store_id": 1,
  "user_id": 123,
  "recommendations": [
    {
      "item_id": 456,
      "variant_id": 456,
      "score": 0.89,
      "rank": 1
    }
  ]
}
```

### Predict Trending

```http
POST /predict/trending
Content-Type: application/json

{
  "store_id": 1,
  "n": 20
}
```

**Response:**

```json
{
  "store_id": 1,
  "trending": [
    {
      "item_id": 789,
      "variant_id": 789,
      "predicted_sales": 45.6,
      "trend_score": 2.3,
      "rank": 1
    }
  ]
}
```

### Predict Next Items

```http
POST /predict/next-items
Content-Type: application/json

{
  "store_id": 1,
  "item_history": [100, 200, 300],
  "top_k": 10
}
```

**Response:**

```json
{
  "store_id": 1,
  "input_history": [100, 200, 300],
  "predictions": [
    {
      "item_id": 400,
      "probability": 0.85,
      "confidence": 0.92,
      "support": 45
    }
  ]
}
```

## âš™ï¸ Cáº¥u hÃ¬nh

Táº¥t cáº£ cáº¥u hÃ¬nh Ä‘Æ°á»£c quáº£n lÃ½ qua biáº¿n mÃ´i trÆ°á»ng trong file `.env`:

### Database

- `DB_HOST`: Host PostgreSQL (default: localhost)
- `DB_PORT`: Port PostgreSQL (default: 5433)
- `DB_NAME`: TÃªn database (default: testocm)
- `DB_USER`: Username (default: zalolog)
- `DB_PASSWORD`: Password

### Flask

- `FLASK_HOST`: Host Ä‘á»ƒ bind (default: 0.0.0.0)
- `FLASK_PORT`: Port Ä‘á»ƒ listen (default: 5001)
- `FLASK_DEBUG`: Debug mode (default: false)

### Model Hyperparameters

Xem file `.env.example` Ä‘á»ƒ biáº¿t táº¥t cáº£ cÃ¡c hyperparameters cÃ³ thá»ƒ cáº¥u hÃ¬nh.

## ğŸ“ Cáº¥u trÃºc thÆ° má»¥c

```
ai-service/
â”œâ”€â”€ api/                          # API service code
â”‚   â”œâ”€â”€ training_service.py      # Flask app chÃ­nh
â”‚   â”œâ”€â”€ config.py                # Configuration management
â”‚   â”œâ”€â”€ database.py              # Database utilities
â”‚   â”œâ”€â”€ data_extraction.py       # Data extraction tá»« DB
â”‚   â”œâ”€â”€ cache_manager.py         # Cache management
â”‚   â””â”€â”€ trainers/                # Model trainers
â”‚       â”œâ”€â”€ recommendation.py    # NeuMF trainer
â”‚       â”œâ”€â”€ trending.py          # LightGBM trainer
â”‚       â””â”€â”€ next_item.py         # Sequential trainer
â”œâ”€â”€ src/                         # Source code
â”‚   â”œâ”€â”€ data/                    # Data preprocessing
â”‚   â””â”€â”€ evaluation/              # Model evaluation
â”œâ”€â”€ scripts/                     # Utility scripts
â”œâ”€â”€ data/                        # Data files
â”‚   â””â”€â”€ splits/                  # Train/test splits
â”œâ”€â”€ results/                     # Trained models (generated)
â”œâ”€â”€ requirements.txt             # Python dependencies
â”œâ”€â”€ Dockerfile                   # Docker image definition
â”œâ”€â”€ docker-compose.yml           # Docker Compose config
â”œâ”€â”€ env.example                  # Environment template
â””â”€â”€ README.md                    # This file
```

## ğŸ”§ Troubleshooting

### Lá»—i káº¿t ná»‘i database

```bash
# Kiá»ƒm tra PostgreSQL Ä‘ang cháº¡y
psql -h localhost -p 5433 -U zalolog -d testocm

# Kiá»ƒm tra biáº¿n mÃ´i trÆ°á»ng
echo $DB_HOST
```

### Lá»—i thiáº¿u dependencies

```bash
# Reinstall dependencies
pip install -r requirements.txt --force-reinstall
```

### Lá»—i out of memory khi training

- Giáº£m `RECOMMENDATION_BATCH_SIZE`
- Giáº£m `RECOMMENDATION_EPOCHS`
- TÄƒng RAM hoáº·c sá»­ dá»¥ng GPU

### Model khÃ´ng Ä‘Æ°á»£c lÆ°u

- Kiá»ƒm tra quyá»n ghi vÃ o thÆ° má»¥c `results/`
- Kiá»ƒm tra disk space: `df -h`

## ğŸ“ Notes

- Models Ä‘Æ°á»£c lÆ°u theo store: `results/store_{store_id}/{model_type}/`
- Cache Ä‘Æ°á»£c quáº£n lÃ½ tá»± Ä‘á»™ng vá»›i expiry time
- Training logs Ä‘Æ°á»£c lÆ°u vÃ o database table `ai_training_log`
- Service status Ä‘Æ°á»£c cáº­p nháº­t trong `store_ai_status`

## ğŸ“„ License

[ThÃªm license náº¿u cÃ³]

## ğŸ‘¥ Contributors

[ThÃªm contributors náº¿u cÃ³]
